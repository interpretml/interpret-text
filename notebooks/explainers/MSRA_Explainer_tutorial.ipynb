{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import logging\n",
    "import shap\n",
    "import torch\n",
    "import json\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from urllib import request\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "\n",
    "from interpret_text.msra.MSRAExplainer import MSRAExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./temp\"\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to generate embeddings for BERT Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_bert(text, device):\n",
    "    # get the tokenized words.\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    words = [\"[CLS]\"] + tokenizer.tokenize(text) + [\"[SEP]\"]\n",
    "    tokenized_ids = tokenizer.convert_tokens_to_ids(words)\n",
    "    segment_ids = [0 for _ in range(len(words))]\n",
    "    token_tensor = torch.tensor([tokenized_ids], device=device)\n",
    "    segment_tensor = torch.tensor([segment_ids], device=device)\n",
    "    x_bert = model.embeddings(token_tensor, segment_tensor)[0]\n",
    "    return x_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the BERT base model with the saved finetuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the finetuned parameters\n",
    "model_state_dict = torch.load(\"models/model.pth\")\n",
    "#Load BERT base model with the finetuned parameters\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", state_dict=model_state_dict)\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the embeddings for the input text and initialize the interpreter. We also calculate the regularization parameter required by the MSR Asia Explainer using the function provided by the Explainer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"rare bird has more than enough charm to make it memorable.\"\n",
    "embedded_input = embeddings_bert(text, device)\n",
    "interpreter_msra = MSRAExplainer(device=device)\n",
    "regularization = interpreter_msra.getRegularizationBERT(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call explain_local on the interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:54<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1879063993692398, 0.14912039041519165, 0.1531413346529007, 0.2352224886417389, 0.21313492953777313, 0.21833769977092743, 0.19894209504127502, 0.13736814260482788, 0.2685736417770386, 0.23845000565052032, 0.25325438380241394, 0.1364051103591919, 0.29170724749565125, 0.37515968084335327]\n"
     ]
    }
   ],
   "source": [
    "explanation_msra = interpreter_msra.explain_local(model=model, embedded_input=embedded_input, regularization=regularization)\n",
    "print(explanation_msra.local_importance_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic visualization until the visualization dashboard is fully integrated as a python widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.4035184383392334);\">rare</span> <span style=\"background-color:rgba(135,206,250,0.3874346613883972);\">bird</span> <span style=\"background-color:rgba(135,206,250,0.059110045433044434);\">has</span> <span style=\"background-color:rgba(135,206,250,0.14746028184890747);\">more</span> <span style=\"background-color:rgba(135,206,250,0.12664920091629028);\">than</span> <span style=\"background-color:rgba(135,206,250,0.2042316198348999);\">enough</span> <span style=\"background-color:rgba(135,206,250,0.4505274295806885);\">charm</span> <span style=\"background-color:rgba(250,0,0,0.0742945671081543);\">to</span> <span style=\"background-color:rgba(135,206,250,0.0461999773979187);\">make</span> <span style=\"background-color:rgba(250,0,0,0.013017535209655762);\">it</span> <span style=\"background-color:rgba(135,206,250,0.4543795585632324);\">memorable</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpreter_msra.visualize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (interpret-text)",
   "language": "python",
   "name": "interpret-text-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
